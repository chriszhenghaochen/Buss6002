{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>BUSS6002 - Data Science in Business</h1></center>\n",
    "\n",
    "#### Pre-Tutorial Checklist\n",
    "\n",
    "1. Complete Task 1 and Task 2 from Week 10\n",
    "\n",
    "# Tutorial 11 - Text Analytics\n",
    "\n",
    "## Text Analytics\n",
    "\n",
    "Often the data that we need to analyse is textual. Text data is incompatible with the models we have discussed so far because the models require numeric values. For example we don't have a direct numeric distance between the words \"hello\" and \"friend\". \n",
    "\n",
    "Moreover sometimes single data points such as a tweet, facebook post etc will contain a large number of words. So we need a way to convert the text data into a flexible numeric representation. This representation should tell us which words occured and how many times.\n",
    "\n",
    "\n",
    "## Bag-of-Words\n",
    "\n",
    "The bag-of-words (BoW) model is a simple method of transforming strings into a numeric representation. BoW treats each word as a feature and the value of the feature is the number of times it occurds.\n",
    "\n",
    "\n",
    "For example the string\n",
    "\n",
    "    \"The quick brown fox jumps over the lazy dog\"\n",
    "    \n",
    "would be transformed into\n",
    "\n",
    "| the | quick | brown | fox | jumps | over | lazy | dog |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "| 2 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n",
    "\n",
    "Note that:\n",
    "- the word \"the\" occurs twice so its count is 2\n",
    "- other words are unique so they only occur once\n",
    "- the number of features is the number of unique words\n",
    "\n",
    "To create a BoW set of features\n",
    "\n",
    "<div style=\"margin-bottom: 0px;\"><img width=20 style=\"display: block; float: left;  margin-right: 20px;\" src=\"img/docs.png\"> <h3 style=\"padding-top: 0px;\">Documentation - CountVectorizer</h3></div>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = [\"The quick brown fox jumps over the lazy dog\",\n",
    "          \"Another dog ran after the fox\"]\n",
    "\n",
    "X = count_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a sparse matrix. To view it we need to convert it to a dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 1 1 1 1 0 2]\n",
      " [1 1 0 1 1 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 10)\t2\n",
      "  (1, 0)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 10)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix isn't that helpful by itself. Lets look at the corresponding feature names (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['after', 'another', 'brown', 'dog', 'fox', 'jumps', 'lazy', 'over', 'quick', 'ran', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets combine everything into a DataFrame for clarity. You don't always have to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   after  another  brown  dog  fox  jumps  lazy  over  quick  ran  the\n",
      "0      0        0      1    1    1      1     1     1      1    0    2\n",
      "1      1        1      0    1    1      0     0     0      0    1    1\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Another dog ran after the fox\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TRNASFORM THE FEATURES TO PANDAS DATASET\n",
    "features = pd.DataFrame(X.todense(), columns = count_vectorizer.get_feature_names())\n",
    "\n",
    "print(features)\n",
    "\n",
    "corpus = [\"The quick brown fox jumps over the lazy dog\",\n",
    "          \"Another dog ran after the fox\"]\n",
    "\n",
    "print(corpus[0])\n",
    "print(corpus[1])\n",
    "\n",
    "\n",
    "# importT:from sklearn.feature_extraction.text import CountVectorizer\n",
    "# use .fit_transform: X = count_vectorizer.fit_transform(corpus) \n",
    "# print the content of features from the X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e.g. if I want to calculate tf.idf for brown\n",
    "# tf_brown_1 = 1\n",
    "# tf_brown_2 = 0\n",
    "\n",
    "# idf_brow = log(2/1) = log2\n",
    "\n",
    "# tf_idf_brown_1 = 1*log2\n",
    "# tf_idf_brown_2 = 0*log2\n",
    "\n",
    "# in this example we use the simplest version of tf-idf, use boolean counting for tf, and simple log(N/n_d) with idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TF-IDF\n",
    "\n",
    "In text data there will be lots of repeated words such as \"a\", \"is\" and \"the\" that aren't very useful. We should ignore them as much as possible.\n",
    "\n",
    "The Term Frequencyâ€“Inverse Document Frequency (TF-IDF) is a weighting procedure for BoW data. The TF-IDF weights boost the counts or frequency of uncommon words (which will be useful) and shrinks the mangitude of common words. There are two components to the TF-IDF weights, and each of these can be calculated in different ways:\n",
    "\n",
    "- Term Frequency, often the _raw count_ of a term in a document $tf = f_D$. Other possibilities are boolean (1 if the term appears, otherwise 0), length adjusted ($tf = \\frac{f_D}{n_{words}}$) or logarithmic ($tf = \\log(1+f_D)$).\n",
    "\n",
    "- Inverse Document Frequency, or a measure of the information contained in a word. This is a penalty for commonly used words like 'a' and 'the'. It's the logarithmically scaled inverse fraction of the documents that contain the word (obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient). $idf = \\log(\\frac{N}{n_D})$ where $N$ is the number of documents and $n_D$ is the number of documents in which the word appears.\n",
    "\n",
    "The tfidf score is calculated as follows:\n",
    "\n",
    "$$tfidf = tf \\cdot idf $$\n",
    "\n",
    "## TF-IDF in Sklearn\n",
    "\n",
    "Let's vectorise a collection of documents. Notice that each line is treated as a document in this case, so our corpus is a total of 4 documents. \n",
    "\n",
    "<div style=\"margin-bottom: 0px;\"><img width=20 style=\"display: block; float: left;  margin-right: 20px;\" src=\"img/docs.png\"> <h3 style=\"padding-top: 0px;\">Documentation - TfidfVectorizer</h3></div>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [\"The quick brown fox jumps over the lazy dog\",\n",
    "          \"Another dog ran after the fox\",\n",
    "          \"The world is turning\",\n",
    "          \"Hello world\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectoriser = TfidfVectorizer() # they might using some complicated parameters to count the tf-idf features.\n",
    "\n",
    "X = tfidf_vectoriser.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>another</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>hello</th>\n",
       "      <th>is</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>ran</th>\n",
       "      <th>the</th>\n",
       "      <th>turning</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.280988</td>\n",
       "      <td>0.280988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454968</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.295980</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366747</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.453005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785288</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.619130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      after   another     brown       dog       fox     hello       is  \\\n",
       "0  0.000000  0.000000  0.356398  0.280988  0.280988  0.000000  0.00000   \n",
       "1  0.463709  0.463709  0.000000  0.365594  0.365594  0.000000  0.00000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.57458   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.785288  0.00000   \n",
       "\n",
       "      jumps      lazy      over     quick       ran       the  turning  \\\n",
       "0  0.356398  0.356398  0.356398  0.356398  0.000000  0.454968  0.00000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.463709  0.295980  0.00000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.366747  0.57458   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "\n",
       "      world  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.453005  \n",
       "3  0.619130  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(X.todense(), columns = tfidf_vectoriser.get_feature_names())\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom: 30px;\"><img width=48 style=\"display: block; float: left;  margin-right: 20px;\" src=\"img/question-mark-button.png\"> <h3 style=\"padding-top: 15px;\">Exercise 1 - TF-IDF weights calculation</h3></div>\n",
    "\n",
    "In the corpus with two documents:\n",
    "\n",
    "``On the 24th of February, 1815, the lookâ€“out at Notreâ€“Dame de la Garde signalled the threeâ€“master, the Pharaon from Smyrna, Trieste, and Naples.``\n",
    "\n",
    "``As usual, a pilot put off immediately, and rounding the Chateau dâ€™If, got on board the vessel between Cape Morgion and Rion island.``\n",
    "\n",
    "Find the TF-IDF weights for the words ``the`` and ``Trieste`` by code or by hand. For term frequency, try Boolean weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to use hand\n",
    "# N = 2\n",
    "# we use  Boolean weights, if the words shows it should be 1, otherwise 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "For ``the``: $tf_1 = 1$, $tf_2 = 1$, $idf = \\log(2/2) = 0$\n",
    "\n",
    "So for both documents, $tfidf = 0$\n",
    "\n",
    "For ``Trieste``: $tf_1 = 1$, $tf_2 = 0$, $idf = \\log(2/1) = 0.7$\n",
    "\n",
    "So for document 1, $tfidf = 0.7$, for document 2 $tfidf = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20h20 hours ago</td>\n",
       "      <td>786982739517943808</td>\n",
       "      <td>/BarackObama/status/786982739517943808</td>\n",
       "      <td>False</td>\n",
       "      <td>Denying climate change is dangerous. Join @OFA...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18h18 hours ago</td>\n",
       "      <td>787010142378332160</td>\n",
       "      <td>/BarackObama/status/787010142378332160</td>\n",
       "      <td>False</td>\n",
       "      <td>The American Bar Association gave Judge Garlan...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16h16 hours ago</td>\n",
       "      <td>787039774330748928</td>\n",
       "      <td>/BarackObama/status/787039774330748928</td>\n",
       "      <td>False</td>\n",
       "      <td>We need a fully functional Supreme Court. Edit...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21h21 hours ago</td>\n",
       "      <td>786964419905523712</td>\n",
       "      <td>/BarackObama/status/786964419905523712</td>\n",
       "      <td>False</td>\n",
       "      <td>Cynics, take note: When we #ActOnClimate, we b...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Oct 13</td>\n",
       "      <td>786680553617629184</td>\n",
       "      <td>/BarackObama/status/786680553617629185</td>\n",
       "      <td>False</td>\n",
       "      <td>\"Thatâ€™s how we will overcome the challenges we...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             date                  id  \\\n",
       "0           0  20h20 hours ago  786982739517943808   \n",
       "1           1  18h18 hours ago  787010142378332160   \n",
       "2           2  16h16 hours ago  787039774330748928   \n",
       "3           3  21h21 hours ago  786964419905523712   \n",
       "4           4           Oct 13  786680553617629184   \n",
       "\n",
       "                                     link  retweet  \\\n",
       "0  /BarackObama/status/786982739517943808    False   \n",
       "1  /BarackObama/status/787010142378332160    False   \n",
       "2  /BarackObama/status/787039774330748928    False   \n",
       "3  /BarackObama/status/786964419905523712    False   \n",
       "4  /BarackObama/status/786680553617629185    False   \n",
       "\n",
       "                                                text       author  \n",
       "0  Denying climate change is dangerous. Join @OFA...  BarackObama  \n",
       "1  The American Bar Association gave Judge Garlan...  BarackObama  \n",
       "2  We need a fully functional Supreme Court. Edit...  BarackObama  \n",
       "3  Cynics, take note: When we #ActOnClimate, we b...  BarackObama  \n",
       "4  \"Thatâ€™s how we will overcome the challenges we...  BarackObama  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Obama tweets set\n",
    "obama = pd.read_csv(\"BarackObama.csv\")\n",
    "\n",
    "obama.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oct 7</td>\n",
       "      <td>784609194234306560</td>\n",
       "      <td>/realDonaldTrump/status/784609194234306560</td>\n",
       "      <td>False</td>\n",
       "      <td>Here is my statement.pic.twitter.com/WAZiGoQqMQ</td>\n",
       "      <td>DonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Oct 10</td>\n",
       "      <td>785608815962099712</td>\n",
       "      <td>/realDonaldTrump/status/785608815962099712</td>\n",
       "      <td>False</td>\n",
       "      <td>Is this really America? Terrible!pic.twitter.c...</td>\n",
       "      <td>DonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oct 8</td>\n",
       "      <td>784840992734064640</td>\n",
       "      <td>/realDonaldTrump/status/784840992734064641</td>\n",
       "      <td>False</td>\n",
       "      <td>The media and establishment want me out of the...</td>\n",
       "      <td>DonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Oct 8</td>\n",
       "      <td>784767399442653184</td>\n",
       "      <td>/realDonaldTrump/status/784767399442653184</td>\n",
       "      <td>False</td>\n",
       "      <td>Certainly has been an interesting 24 hours!</td>\n",
       "      <td>DonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Oct 10</td>\n",
       "      <td>785561269571026944</td>\n",
       "      <td>/realDonaldTrump/status/785561269571026946</td>\n",
       "      <td>False</td>\n",
       "      <td>Debate polls look great - thank you!\\n#MAGA #A...</td>\n",
       "      <td>DonaldTrump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    date                  id  \\\n",
       "0           0   Oct 7  784609194234306560   \n",
       "1           1  Oct 10  785608815962099712   \n",
       "2           2   Oct 8  784840992734064640   \n",
       "3           3   Oct 8  784767399442653184   \n",
       "4           4  Oct 10  785561269571026944   \n",
       "\n",
       "                                         link  retweet  \\\n",
       "0  /realDonaldTrump/status/784609194234306560    False   \n",
       "1  /realDonaldTrump/status/785608815962099712    False   \n",
       "2  /realDonaldTrump/status/784840992734064641    False   \n",
       "3  /realDonaldTrump/status/784767399442653184    False   \n",
       "4  /realDonaldTrump/status/785561269571026946    False   \n",
       "\n",
       "                                                text       author  \n",
       "0    Here is my statement.pic.twitter.com/WAZiGoQqMQ  DonaldTrump  \n",
       "1  Is this really America? Terrible!pic.twitter.c...  DonaldTrump  \n",
       "2  The media and establishment want me out of the...  DonaldTrump  \n",
       "3        Certainly has been an interesting 24 hours!  DonaldTrump  \n",
       "4  Debate polls look great - thank you!\\n#MAGA #A...  DonaldTrump  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trump tweets set\n",
    "trump = pd.read_csv(\"DonaldTrumpTweets.csv\")\n",
    "\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6896, 11064)\n"
     ]
    }
   ],
   "source": [
    "# Lets apply a tfidf transformation to Obama's tweets to check for any\n",
    "# weird words/phrases that might cause problems\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = obama['text']\n",
    "\n",
    "test_vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "tfidf = test_vectorizer.fit_transform(corpus)\n",
    "print(tfidf.shape)\n",
    "# print(test_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6896, 6646)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "corpus = corpus.apply(lambda x: re.sub(r\"http\\S+|pic.twitter.com\\S+\", '', x, flags=re.IGNORECASE))\n",
    "\n",
    "# tf-dif\n",
    "test_vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "tfidf = test_vectorizer.fit_transform(corpus)\n",
    "print(tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17216, 12482)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "corpus = trump['text']\n",
    "\n",
    "corpus = corpus.apply(lambda x: re.sub(r\"http\\S+|pic.twitter.com\\S+|@\\S+\", '', x, flags=re.IGNORECASE))\n",
    "\n",
    "test_vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "tfidf = test_vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17216, 2)\n",
      "(6896, 2)\n",
      "(24112, 2)\n"
     ]
    }
   ],
   "source": [
    "# Mark which tweets belong to which person\n",
    "# print(trump.head())\n",
    "trump['class'] = 1 # if this tweet belong to trump we assign it to class 1\n",
    "obama['class'] = 0 # otherwise, it is class 0\n",
    "\n",
    "print(trump[['text', 'class']].values.shape)\n",
    "print(obama[['text', 'class']].values.shape)\n",
    "\n",
    "\n",
    "# Combine the trump and obama tweets into a single dataframe\n",
    "data = pd.concat( [trump[['text', 'class']], obama[['text', 'class']]], axis = 0 )\n",
    "print(data.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here is my statement.pic.twitter.com/WAZiGoQqMQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is this really America? Terrible!pic.twitter.c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The media and establishment want me out of the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Certainly has been an interesting 24 hours!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debate polls look great - thank you!\\n#MAGA #A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0    Here is my statement.pic.twitter.com/WAZiGoQqMQ      1\n",
       "1  Is this really America? Terrible!pic.twitter.c...      1\n",
       "2  The media and establishment want me out of the...      1\n",
       "3        Certainly has been an interesting 24 hours!      1\n",
       "4  Debate polls look great - thank you!\\n#MAGA #A...      1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "# unprocessing feature text and label class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick up ALL the tweets\n",
    "corpus = data['text']\n",
    "\n",
    "# Fix the tweets get rid of the useless words\n",
    "corpus = corpus.apply(lambda x: re.sub(r\"http\\S+|pic.twitter.com\\S+|@\\S+\", '', x, flags=re.IGNORECASE))\n",
    "\n",
    "# call the class of TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "# transfer the raw text to tf.idf feature\n",
    "tfidf_data = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18084, 14595)\n",
      "(18084,)\n",
      "(6028, 14595)\n",
      "(6028,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train/Test split the dataset\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(tfidf_data, data['class'])\n",
    "\n",
    "# x is feature, y is label\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "\n",
    "# we have 18084 rows of training data\n",
    "\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)\n",
    "\n",
    "# and then we evaluate in 6028 testing data to see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# call \n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# fit\n",
    "log_reg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.77      0.85      1766\n",
      "          1       0.91      0.98      0.94      4262\n",
      "\n",
      "avg / total       0.92      0.92      0.92      6028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ytest_preds = log_reg.predict(Xtest)\n",
    "\n",
    "print(classification_report(ytest, ytest_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1365,  401],\n",
       "       [  96, 4166]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(ytest, ytest_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
